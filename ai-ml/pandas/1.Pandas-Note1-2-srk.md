# Pandas Tutorial - Complete Guide

## Table of Contents

### Level 1: Fundamentals
- [Introduction](#introduction)
  - Importing Libraries
- [Pandas Series](#pandas-series)
  - What is a Series?
  - Creating Series from List
  - Creating Series with Custom Index
  - Creating Series from 1D Array
  - Creating Series from Dictionary
- [Pandas DataFrame](#pandas-dataframe)
  - What is a DataFrame?
  - Creating DataFrame from Dictionary
  - Creating DataFrame from Nested List
  - Creating DataFrame from 2D Array
- [DataFrame Operations](#dataframe-operations)
  - Index Operations (set_index, reset_index)
  - Drop Operations (rows and columns)
  - Sorting Values (ascending and descending)
- [Combining DataFrames](#combining-dataframes)
  - Concatenation (axis=0 and axis=1)
  - Using ignore_index
- [Merging DataFrames](#merging-dataframes)
  - Left Join
  - Right Join
  - Inner Join
  - Outer Join

### Level 2: Advanced Operations
- [Loading Data](#loading-data)
  - Reading CSV Files
  - Reading Excel Files
  - Viewing Data (head, tail)
- [DataFrame Inspection](#dataframe-inspection)
  - Viewing Columns and Data Types
  - Checking for Null Values
  - Renaming Columns
- [Data Selection and Indexing](#data-selection-and-indexing)
  - Selecting Single Column (Series vs DataFrame)
  - Converting Series to Array
  - Using iloc() - Position-based Indexing
  - Using loc() - Label-based Indexing
- [Data Filtering](#data-filtering)
  - Single Condition Filtering
  - Multiple Conditions (AND/OR)
  - Negation Filtering
- [Data Analysis](#data-analysis)
  - Unique Values
  - Value Counts
  - Crosstab Analysis
  - Group By Operations
- [Best Practices and Tips](#best-practices-and-tips)

---

## Introduction

### Import Libraries
```python
import numpy as np
import pandas as pd
```

---

## Pandas Series

### What is a Pandas Series?
- A one-dimensional (1D) array holding data of any type
- Similar to a column in a table

### 1. Creating Series from a List

```python
l = [10, 20, 30]
s = pd.Series(l)
print(s)
```

**Output:**
```
0    10
1    20
2    30
dtype: int64
```

**Check type:**
```python
type(s)  # pandas.core.series.Series
```

**Check shape:**
```python
s.shape  # (3,)
```

### 2. Creating Series with Custom Index

```python
l = [10, 20, 30]
s = pd.Series(l, index=["a", "b", "c"])
print(s)
```

**Output:**
```
a    10
b    20
c    30
dtype: int64
```

### 3. Creating Series from 1D Array

```python
a = np.array([10, 20, 30])
s = pd.Series(a)
print(s)
```

**Output:**
```
0    10
1    20
2    30
dtype: int32
```

**With custom index:**
```python
a = np.array([10, 20, 30])
s = pd.Series(a, index=["a", "b", "c"])
print(s)
```

**Output:**
```
a    10
b    20
c    30
dtype: int32
```

### 4. Creating Series from Dictionary

```python
d = {'a': 10, 'b': 20, 'c': 30}
s = pd.Series(d)
print(s)
```
- It will create index (key) and column (value)
**Output:**
```
a    10
b    20
c    30
dtype: int64
```

---

## Pandas DataFrame

### What is a DataFrame?
- A 2-dimensional data structure (like a 2D array or table)
- Contains rows and columns

### 1. Creating DataFrame from Dictionary

**Basic example:**
```python
d = {'col1': [1, 2], 'col2': [3, 4]}
s = pd.Series(d)
print(s)
```

**Output:**
```
col1    [1, 2]
col2    [3, 4]
dtype: object
```

**Creating actual DataFrame:**
```python
d = {'col1': [1, 2], 'col2': [3, 4]}
df = pd.DataFrame(d)
df
```

**Output:**
```
   col1  col2
0     1     3
1     2     4
```

**Check type:**
```python
type(df)  # pandas.core.frame.DataFrame
```

**Check shape:**
```python
df.shape  # (2, 2)
```

### 2. Creating DataFrame from Nested List
- Custom `column` names
```python
data = [[1, 2, 3], [4, 5, 6]]
df1 = pd.DataFrame(data, columns=["a", "b", "c"])
df1
```

**Output:**
```
   a  b  c
0  1  2  3
1  4  5  6
```

### 3. Creating DataFrame from 2D Array
- Custom `column` names
- Custom `index` name
```python
arr_2d = np.array([[1, 2, 3], [4, 5, 6]])
df2 = pd.DataFrame(arr_2d, index=["a", "b"], columns=["s", "r", "k"])
df2
```

**Output:**
```
   s  r  k
a  1  2  3
b  4  5  6
```

---

## DataFrame Operations

### Sample DataFrame

```python
df = pd.DataFrame({
    'Age': [22, 30, 23, 25, 24],
    'Salary': [28000, 17000, 46000, 42000, 55000],
    'Gender': ["M", "F", "M", "M", "F"]
})
df
```

**Output:**
```
   Age  Salary Gender
0   22   28000      M
1   30   17000      F
2   23   46000      M
3   25   42000      M
4   24   55000      F
```

### Index Operations
- Set Column's age/ salary as `Index` for operations
#### Set Index
```python
df1 = df.set_index("Age")
df1
```

**Output:**
```
     Salary Gender
Age                
22    28000      M
30    17000      F
23    46000      M
25    42000      M
24    55000      F
```

#### Reset Index
```python
df1.reset_index()
```

**Output:**
```
   Age  Salary Gender
0   22   28000      M
1   30   17000      F
2   23   46000      M
3   25   42000      M
4   24   55000      F
```

### Drop Operations

#### Drop Single Row
```python
df1 = df.drop(index=[3])
print(df1)
```

**Output:**
```
   Age  Salary Gender
0   22   28000      M
1   30   17000      F
2   23   46000      M
4   24   55000      F
```

#### Drop Multiple Rows
```python
df1 = df.drop(index=[0, 1, 2])
df1
```

**Output:**
```
   Age  Salary Gender
3   25   42000      M
4   24   55000      F
```

#### Drop Single Column
```python
df1 = df.drop(columns=["Age"])
df1
```

**Output:**
```
   Salary Gender
0   28000      M
1   17000      F
2   46000      M
3   42000      M
4   55000      F
```

#### Drop Multiple Columns
- Drop both row and columns: `df1 = df1.drop(index=[0,2,3], columns=["Gender"])`
```python
df1 = df.drop(columns=["Age", "Gender"])
df1
```

**Output:**
```
   Salary
0   28000
1   17000
2   46000
3   42000
4   55000
```

### Sorting Values

#### Ascending Order
```python
# Sorting in ascending order
df.sort_values(by='Age', ascending=True)
```

**Output:**
```
   Age  Salary Gender
0   22   28000      M
2   23   46000      M
4   24   55000      F
3   25   42000      M
1   30   17000      F
```

#### Descending Order
```python
# Sorting in descending order
df.sort_values(by='Age', ascending=False)
```

**Output:**
```
   Age  Salary Gender
1   30   17000      F
3   25   42000      M
4   24   55000      F
2   23   46000      M
0   22   28000      M
```

---

## Combining DataFrames

### Sample DataFrames

**DataFrame 1:**
```python
df1 = pd.DataFrame({
    "city": ["mumbai", "delhi", "banglore", "hyderabad"],
    "temperature": [32, 45, 40, 36]
})
df1
```

**Output:**
```
       city  temperature
0    mumbai           32
1     delhi           45
2  banglore           40
3  hyderabad          36
```

**DataFrame 2:**
```python
df2 = pd.DataFrame({
    "city": ["delhi", "mumbai", "banglore", "chennai"],
    "humidity": [68, 65, 75, 70]
})
df2
```

**Output:**
```
       city  humidity
0     delhi        68
1    mumbai        65
2  banglore        75
3   chennai        70
```

### Concatenation
I. When to use `pd.concat()`:
Use `concat` when you have multiple DataFrames with the same structure.
- **Vertical Stacking (Most Common)**: You have "January Sales" and "February Sales" and you want one long list.

- **Horizontal Stacking**: You have the same rows but different columns (and they are already in the correct order).

II. When to use `pd.merge()`:
Use merge when you want to combine DataFrames based on a common column **(a "key")**, even if the rows are in a different order. This is exactly like an **SQL Join.**
- **Linking Data:** You have a "Sales" table and a "Product Info" table, and both share a ProductID column.

- **Complex Relationships:** You need to handle One-to-Many or Many-to-Many relationships.

#### Concatenate along rows (axis=1)
```python
pd.concat([df1, df2], axis=1)
```

**Output:**
```
       city  temperature      city  humidity
0    mumbai           32     delhi        68
1     delhi           45    mumbai        65
2  banglore           40  banglore        75
3  hyderabad          36   chennai        70
```

#### Concatenate along columns (axis=0)
```python
pd.concat([df1, df2], axis=0)
```

**Output:**
```
       city  temperature  humidity
0    mumbai         32.0       NaN
1     delhi         45.0       NaN
2  banglore         40.0       NaN
3  hyderabad        36.0       NaN
0     delhi          NaN      68.0
1    mumbai          NaN      65.0
2  banglore          NaN      75.0
3   chennai          NaN      70.0
```

#### Concatenate with ignore_index=True
```python
pd.concat([df1, df2], ignore_index=True)
```

**Output:**
```
       city  temperature  humidity
0    mumbai         32.0       NaN
1     delhi         45.0       NaN
2  banglore         40.0       NaN
3  hyderabad        36.0       NaN
4     delhi          NaN      68.0
5    mumbai          NaN      65.0
6  banglore          NaN      75.0
7   chennai          NaN      70.0
```

---

## Merging DataFrames

When using merge, you must decide the how parameter:

**Inner (default):** Only keep rows where the key exists in both tables.

**Left:** Keep everything from the first table, add matching info from the second.

**Right:** Keep everything from the second table, add matching info from the first.

**Outer:** Keep everything from both tables (fills missing spots with `NaN`).

### Left Join
```python
# Left Join -- Left columns & common data records from Right only
left_df = pd.merge(df1, df2, on='city', how='left')
left_df
```

**Output:**
```
       city  temperature  humidity
0    mumbai           32      65.0
1     delhi           45      68.0
2  banglore           40      75.0
3  hyderabad          36       NaN
```

### Right Join
```python
# Right Join -- Right columns & common data records from Left only
right_df = pd.merge(df1, df2, on='city', how='right')
right_df
```

**Output:**
```
       city  temperature  humidity
0     delhi         45.0        68
1    mumbai         32.0        65
2  banglore         40.0        75
3   chennai          NaN        70
```

### Inner Join
```python
# Inner Join -- common data records
inner_df = pd.merge(df1, df2, on="city", how="inner")
inner_df
```

**Output:**
```
       city  temperature  humidity
0    mumbai           32        65
1     delhi           45        68
2  banglore           40        75
```

### Outer Join
```python
# Outer Join -- all records of both dataframes
outer_df = pd.merge(df1, df2, on='city', how='outer')
outer_df
```

**Output:**
```
       city  temperature  humidity
0    mumbai         32.0      65.0
1     delhi         45.0      68.0
2  banglore         40.0      75.0
3  hyderabad        36.0       NaN
4   chennai          NaN      70.0
```

---

# Level 2: Advanced Operations

## Loading Data

### Reading CSV Files

**Option 1: With full path**
```python
df = pd.read_csv("C:\\01. Python\\tips.csv")
```

**Option 2: Just filename (if in same directory)**
```python
# No package installation required
df = pd.read_csv("tips.csv")
```

### Reading Excel Files

```python
# Package required: `pip install openpyxl`
df = pd.read_excel("tips.xlsx")
```

### Viewing Data

#### Head - First 5 rows
```python
df.head() # Default 5 rows
df.head(10) # First 10 rows
```

**Output:**
```
   total_bill   tip     sex smoker  day    time  size
0       16.99  1.01  Female     No  Sun  Dinner     2
1       10.34  1.66    Male     No  Sun  Dinner     3
2       21.01  3.50    Male     No  Sun  Dinner     3
3       23.68  3.31    Male     No  Sun  Dinner     2
4       24.59  3.61  Female     No  Sun  Dinner     4
```

#### Tail - Last 5 rows
```python
df.tail() # Default 5 rows
df.tail(10) # Last 10 rows
```

**Output:**
```
     total_bill   tip     sex smoker   day    time  size
239       29.03  5.92    Male     No   Sat  Dinner     3
240       27.18  2.00  Female    Yes   Sat  Dinner     2
241       22.67  2.00    Male    Yes   Sat  Dinner     2
242       17.82  1.75    Male     No   Sat  Dinner     2
243       18.78  3.00  Female     No  Thur  Dinner     2
```

---

## DataFrame Inspection

### Viewing Column Names

```python
df.columns
```

**Output:**
```
Index(['total_bill', 'tip', 'sex', 'smoker', 'day', 'time', 'size'], dtype='object')
```

**Alternative method:**
```python
df.keys()
```

**Output:**
```
Index(['total_bill', 'tip', 'sex', 'smoker', 'day', 'time', 'size'], dtype='object')
```

### Renaming Columns

```python
df = df.rename(columns={'sex': 'gender', 'size': 'no_of_members'})
df.columns
```

**Output:**
```
Index(['total_bill', 'tip', 'gender', 'smoker', 'day', 'time', 'no_of_members'], dtype='object')
```

### Checking Data Types

```python
df.dtypes
```

**Output:**
```
total_bill       float64
tip              float64
gender            object
smoker            object
day               object
time              object
no_of_members      int64
dtype: object
```

### Checking for Null Values

```python
df.isnull().sum()
```

**Output:**
```
total_bill       0
tip              0
gender           0
smoker           0
day              0
time             0
no_of_members    0
dtype: int64
```

---

## Data Selection and Indexing

### Selecting a Single Column

#### Returns a Series
```python
df["total_bill"]
```

**Output:**
```
0      16.99
1      10.34
2      21.01
3      23.68
4      24.59
       ...
240    27.18
241    22.67
242    17.82
243    18.78
Name: total_bill, Length: 244, dtype: float64
```

#### Returns a DataFrame
```python
df[["total_bill"]]
```

**Output:**
```
     total_bill
0         16.99
1         10.34
2         21.01
3         23.68
4         24.59
...         ...
240       27.18
241       22.67
242       17.82
243       18.78

244 rows × 1 columns
```

### Converting Series to NumPy Array

```python
df['total_bill'].values
```

**Output:**
```python
array([16.99, 10.34, 21.01, 23.68, 24.59, ..., 27.18, 22.67, 17.82, 18.78])
```

### Selecting Multiple Columns

```python
df[["gender", "smoker"]]
```

**Output:**
```
     gender smoker
0    Female     No
1      Male     No
2      Male     No
3      Male     No
4    Female     No
...     ...    ...
240  Female    Yes
241    Male    Yes
242    Male     No
243  Female     No

244 rows × 2 columns
```

---

### Pandas Data Selection Cheat Sheet
### 1. By Label Name (using `.loc`)

This is the safest way to write code because even if you move your columns around in Excel, the names stay the same.

| Selection | Syntax | Result Type |
| :--- | :--- | :--- |
| **Single Column** | `df.loc[:, "Age"]` | Series (All rows, 1 column) |
| **Single Column (Table)** | `df.loc[:, ["Age"]]` | DataFrame (All rows, 1 column) |
| **Multiple Columns** | `df.loc[:, ["Age", "Salary"]]` | DataFrame (All rows, 2 columns) |
| **Range of Columns** | `df.loc[:, "Age":"Gender"]` | DataFrame (All rows, columns between them) |
| **Single Row** | `df.loc[3, :]` | Series (Row with label/index 3, all columns) |
| **Multiple Rows** | `df.loc[[1, 3, 5], :]` | DataFrame (Rows 1, 3, and 5, all columns) |
| **Range of Rows** | `df.loc[2:5, :]` | DataFrame (Rows 2 through 5, all columns) |

---

### 2. By Index Position (using `.iloc`)

Use this when you want to grab data based on its "address" in the table (0, 1, 2...).

| Selection | Syntax | Result Type |
| :--- | :--- | :--- |
| **Single Column** | `df.iloc[:, 0]` | Series (All rows, 1st column) |
| **Multiple Columns** | `df.iloc[:, [0, 2]]` | DataFrame (All rows, 1st and 3rd columns) |
| **Range of Columns** | `df.iloc[:, 0:3]` | DataFrame (All rows, columns 0, 1, and 2) |
| **Single Row** | `df.iloc[3, :]` | Series (4th row, all columns) |
| **Multiple Rows** | `df.iloc[[1, 3, 5], :]` | DataFrame (2nd, 4th, and 6th rows, all columns) |
| **Range of Rows** | `df.iloc[2:5, :]` | DataFrame (Rows 3 through 5, all columns) |

---

### 3. Combining Row and Column Selection

You are not limited to just rows *or* just columns. You can select specific slices of both at the same time.

#### Using `.loc` (by label)

| Selection | Syntax | Result Type |
| :--- | :--- | :--- |
| **Specific Rows & Columns** | `df.loc[2:5, ["Age", "Salary"]]` | DataFrame (Rows 2-5, only Age and Salary) |
| **Specific Cell** | `df.loc[3, "Age"]` | Single Value (Row 3, Column "Age") |

#### Using `.iloc` (by position)

| Selection | Syntax | Result Type |
| :--- | :--- | :--- |
| **Specific Rows & Columns** | `df.iloc[2:5, [0, 2]]` | DataFrame (Rows 3-5, columns 0 and 2) |
| **Specific Cell** | `df.iloc[3, 1]` | Single Value (Row 4, Column 2) |

---

### 4. Key Syntax Rules to Remember

- **The Comma (`,`):** The syntax is always `[rows, columns]`. Whatever is on the **left** of the comma filters the rows; whatever is on the **right** filters the columns.
- **The Colon (`:`):**
    - `:` alone means "everything" (all rows or all columns).
    - `2:5` means "from 2 up to, but not including, 5" (in `.iloc`).
- **The Square Brackets (`[]`):**
    - **Single value** (e.g., `3` or `"Age"`) $\rightarrow$ Returns a **Series**.
    - **List of values** (e.g., `[3, 5, 7]` or `["Age", "Salary"]`) $\rightarrow$ Returns a **DataFrame**.
- **Counting:**
    - In `.iloc`, the first row and first column are always **0**.
    - In `.loc`, the labels are whatever is in your index/columns (could be numbers, letters, dates, etc.).

## Position-Based Indexing: iloc()

`iloc()` uses **integer positions** to access data (like array indexing).

```python
# Syntax: df.iloc[row_index_start : row_index_stop, column_index]
df.iloc[0:5, 2]
```

### Selecting Single Element

```python
df.iloc[0, 2]
```

**Output:**
```
'Female'
```

### Selecting Single Row

```python
df.iloc[0]
```

**Output:**
```
total_bill     16.99
tip             1.01
gender        Female
smoker            No
day              Sun
time          Dinner
no_of_members      2
Name: 0, dtype: object
```

### Selecting Range of Rows and Specific Column

```python
# Syntax: df.loc[row_index_start : row_index_stop, "Column_Name"]
df.iloc[0:5, 2]
```

**Output:**
```
0    Female
1      Male
2      Male
3      Male
4    Female
Name: gender, dtype: object
```

### Selecting with Step

```python
# Syntax: df.iloc[start:stop:step, column]
# Start (4), Stop (23), Step(6)
df.iloc[4:23:6, 2]
```

**Output:**
```
4     Female
10    Female
16    Female
22      Male
Name: gender, dtype: object
```

### Selecting Specific Rows and Columns

```python
df.iloc[[4, 10, 16, 22], [2, 3]]
```

**Output:**
```
   gender smoker
4  Female     No
10 Female     No
16 Female     No
22   Male    Yes
```

### Selecting All Rows, Specific Column

```python
df.iloc[:, 0]
```

**Output:**
```
0      16.99
1      10.34
2      21.01
...
241    22.67
242    17.82
243    18.78
Name: total_bill, Length: 244, dtype: float64
```

### Selecting All Rows, Multiple Columns

```python
df.iloc[:, [2, 3]]
```

**Output:**
```
     gender smoker
0    Female     No
1      Male     No
2      Male     No
...     ...    ...
241    Male    Yes
242    Male     No
243  Female     No

244 rows × 2 columns
```

---

## Label-Based Indexing: loc()

`loc()` uses **labels/names** to access data.

### Selecting Specific Rows and Columns by Label

```python
df.loc[[4, 10, 16, 22], ["gender", 'smoker']]
```

**Output:**
```
   gender smoker
4  Female     No
10 Female     No
16 Female     No
22   Male    Yes
```

### Selecting with Slice and Step

```python
df.loc[4:23:6, ["gender", 'smoker']]
```

**Output:**
```
   gender smoker
4  Female     No
10 Female     No
16 Female     No
22   Male    Yes
```

### Selecting All Rows, Specific Column

```python
df.loc[:, "total_bill"]
```

**Output:**
```
0      16.99
1      10.34
2      21.01
...
241    22.67
242    17.82
243    18.78
Name: total_bill, Length: 244, dtype: float64
```

### Selecting All Rows, Multiple Columns

```python
df.loc[:, ["gender", 'smoker']]
```

**Output:**
```
     gender smoker
0    Female     No
1      Male     No
2      Male     No
...     ...    ...
241    Male    Yes
242    Male     No
243  Female     No

244 rows × 2 columns
```

---

## Data Filtering

### Single Condition Filtering

```python
df[df["gender"] == "Male"]
```

**Output:**
```
     total_bill   tip  gender smoker   day    time  no_of_members
0         16.99  1.01    Male     No   Sun  Dinner              2
1         10.34  1.66    Male     No   Sun  Dinner              3
...         ...   ...     ...    ...   ...     ...            ...

157 rows × 7 columns
```

**Filter by numeric condition:**
```python
df[df['tip'] >= 7]
```

**Output:**
```
     total_bill    tip  gender smoker  day    time  no_of_members
23        39.42   7.58    Male     No  Sat  Dinner              4
44        30.40   5.60    Male     No  Sun  Dinner              4
...          ...    ...     ...    ...  ...     ...            ...

7 rows × 7 columns
```

### Negation Filtering (NOT)

```python
df[~(df['tip'] >= 7)]
```

**Output:**
```
     total_bill   tip  gender smoker   day    time  no_of_members
0         16.99  1.01  Female     No   Sun  Dinner              2
1         10.34  1.66    Male     No   Sun  Dinner              3
...         ...   ...     ...    ...   ...     ...            ...

237 rows × 7 columns
```

**Alternative:**
```python
df[df['tip'] < 7]
```

### Multiple Conditions

#### AND Condition (&)

```python
df[(df['tip'] >= 3) & (df["gender"] == "Male")]
```

**Output:**
```
     total_bill    tip gender smoker  day    time  no_of_members
2         21.01   3.50   Male     No  Sun  Dinner              3
3         23.68   3.31   Male     No  Sun  Dinner              2
...          ...    ...    ...    ...  ...     ...            ...

76 rows × 7 columns
```

#### OR Condition (|)

```python
df[(df['tip'] >= 3) | (df['gender'] == "Female")]
```

**Output:**
```
     total_bill    tip  gender smoker   day    time  no_of_members
0         16.99   1.01  Female     No   Sun  Dinner              2
2         21.01   3.50    Male     No   Sun  Dinner              3
...          ...    ...     ...    ...   ...     ...            ...

169 rows × 7 columns
```

#### Complex Multiple Conditions

```python
df[(df['tip'] >= 3) & (df['gender'] == "Female") & (df['total_bill'] <= 60)]
```

**Output:**
```
     total_bill   tip  gender smoker   day    time  no_of_members
3         23.68  3.31  Female     No   Sun  Dinner              2
4         24.59  3.61  Female     No   Sun  Dinner              4
11        35.26  5.00  Female     No   Sun  Dinner              4
...          ...   ...     ...    ...   ...     ...            ...

31 rows × 7 columns
```

---

## Data Analysis

### Unique Values

```python
df['gender'].unique()
```

**Output:**
```python
array(['Female', 'Male'], dtype=object)
```

### Value Counts

**Absolute counts:**
```python
df["gender"].value_counts()
```

**Output:**
```
Male      157
Female     87
Name: gender, dtype: int64
```

**Proportions (manual calculation):**
```python
df["gender"].value_counts() / len(df)
```

**Output:**
```
Male      0.643443
Female    0.356557
Name: gender, dtype: float64
```

**Proportions (using normalize parameter): Without dividing by len(df)**
```python
df["gender"].value_counts(normalize=True)
```

**Output:**
```
Male      0.643443
Female    0.356557
Name: gender, dtype: float64
```

### Crosstab Analysis
**Syntax:** `pd.crosstab(index(row), columns)`

- **df["gender"] (The Index):** This will become your Rows. You'll see "`Male`" and "`Female`" on the left.

- **df["smoker"] (The Columns):** This will become your Headers. You'll see "`Yes`" and "`No`" at the top.

#### The "Mapping" Process on crosstab (gender, smoker)

**From `df['gender']` (Rows):**
- Pandas identifies the unique elements: **Male** and **Female**.
- It creates a **Vertical Index** with these two labels.

**From `df['smoker']` (Columns):**
- Pandas identifies the unique elements: **Yes** and **No**.
- It creates a **Horizontal Header** with these two labels.

**The Intersection (Cells):**
- Pandas fills the empty grid by counting how many rows in your Excel file match both criteria (e.g., Row 1 is a Male AND a Smoker $\rightarrow$ add 1 to the "Male-Yes" cell).

**I.** Add Totals with `margins`: If you want to see the total count for each row and column (the "All" category), add **margins=True**

**II.** Get Percentages with `normalize`:
- **normalize='index':** Percentages across the **rows** (totals 100% horizontally).

- **normalize='columns':** Percentages down the **columns** (totals 100% vertically).

**Applied on 2 discrete variables**

**Basic crosstab:**
```python
pd.crosstab(df["gender"], df["smoker"])
```

**Output:**
```
smoker     No  Yes
gender            
Female     54   33
Male       97   60
```

**With row/column totals:**
```python
pd.crosstab(df["gender"], df["smoker"], margins=True)
```

**Output:**
```
smoker     No  Yes  All
gender                 
Female     54   33   87
Male       97   60  157
All       151   93  244
```

### Group By Operations

**Grouping by category and calculating aggregate statistics:**

```python
# Grouping on basis of "gender" and calculating mean of "tip"
df.groupby('gender')["tip"].mean()
```

**Output:**
```
gender
Female    2.833448
Male      3.089618
Name: tip, dtype: float64
```

**Other aggregate functions you can use:**
- `.sum()` - Total sum
- `.mean()` - Average
- `.median()` - Median value
- `.min()` - Minimum value
- `.max()` - Maximum value
- `.count()` - Count of values
- `.std()` - Standard deviation

---

## Key Concepts and Tips

### Level 1: Fundamentals

#### Series
- **Definition**: One-dimensional labeled array
- **Creation methods**: List, NumPy array, dictionary
- **Index**: Can be default (0, 1, 2...) or custom labels
- **Use case**: Represents a single column of data

#### DataFrame
- **Definition**: Two-dimensional labeled data structure
- **Creation methods**: Dictionary, nested list, 2D NumPy array
- **Structure**: Consists of rows (index) and columns
- **Shape**: Access using `.shape` attribute (rows, columns)

#### Index Operations
- **set_index()**: Convert a column to index
- **reset_index()**: Convert index back to regular column
- **Use case**: Useful for organizing and accessing data

#### Drop Operations
- **drop(index=[...])**: Remove rows by index
- **drop(columns=[...])**: Remove columns by name
- **Tip**: Does not modify original DataFrame unless `inplace=True`

#### Sorting
- **sort_values(by='column')**: Sort by specific column
- **ascending=True**: Sort in ascending order (default)
- **ascending=False**: Sort in descending order

#### Concatenation
- **axis=0**: Stack vertically (add rows)
- **axis=1**: Stack horizontally (add columns)
- **ignore_index=True**: Reset index after concatenation

#### Merging
- **on='column'**: Specify the key column for merging
- **how='left'**: Keep all rows from left DataFrame
- **how='right'**: Keep all rows from right DataFrame
- **how='inner'**: Keep only common rows
- **how='outer'**: Keep all rows from both DataFrames

### Level 2: Advanced Operations

#### Loading Data
- **pd.read_csv()**: Load CSV files
- **pd.read_excel()**: Load Excel files
- **Path options**: Full path or just filename (if in same directory)
- **.head()**: View first 5 rows
- **.tail()**: View last 5 rows

#### Column Operations
- **df.columns**: View all column names
- **df.rename()**: Rename columns using dictionary mapping
- **df.dtypes**: Check data type of each column
- **df.isnull().sum()**: Count null values in each column

#### Data Selection
- **df["column"]**: Returns a Series (single brackets)
- **df[["column"]]**: Returns a DataFrame (double brackets)
- **.values**: Convert Series to NumPy array
- **Difference matters**: Series vs DataFrame for further operations

#### iloc() - Position-Based Indexing
- **Uses integer positions**: Like array indexing (0, 1, 2...)
- **df.iloc[row, col]**: Select specific cell
- **df.iloc[rows, cols]**: Use lists or slices
- **Syntax**: `df.iloc[0:5, [1, 3]]` - rows 0-4, columns 1 and 3

#### loc() - Label-Based Indexing
- **Uses labels/names**: Column names and index labels
- **df.loc[index, column]**: Select by name
- **More readable**: Easier to understand what you're selecting
- **Syntax**: `df.loc[:, ["col1", "col2"]]` - all rows, specific columns

#### Filtering Data
- **Single condition**: `df[df["col"] == value]`
- **Multiple AND**: `df[(condition1) & (condition2)]`
- **Multiple OR**: `df[(condition1) | (condition2)]`
- **Negation**: `df[~(condition)]` or inverse condition
- **Numeric comparisons**: `>=`, `<=`, `>`, `<`, `==`, `!=`

#### Data Analysis
- **.unique()**: Get unique values in a column
- **.value_counts()**: Count occurrences of each value
- **normalize=True**: Get proportions instead of counts
- **pd.crosstab()**: Create cross-tabulation of two variables
- **margins=True**: Add row/column totals to crosstab
- **.groupby()**: Group data by category for aggregation

---

## Best Practices

### Level 1
1. **Always check data types** using `type()` and `dtype`
2. **Verify shapes** using `.shape` before operations
3. **Use meaningful column names** for clarity
4. **Set index wisely** for better data access
5. **Choose appropriate merge type** based on your needs:
   - Use **inner** for common records only
   - Use **outer** for all records
   - Use **left/right** when one DataFrame is primary
6. **Handle NaN values** appropriately after merging/concatenating
7. **Use `ignore_index=True`** when concatenating to avoid duplicate indices

### Level 2
1. **Always inspect your data first** using `.head()`, `.tail()`, `.info()`
2. **Check for null values** before analysis using `.isnull().sum()`
3. **Know the difference** between Series and DataFrame selection
4. **Choose between iloc and loc**:
   - Use **iloc** when working with positions/indices
   - Use **loc** when working with labels/names (more readable)
5. **Use parentheses for multiple conditions** in filtering
6. **Remember operator precedence**:
   - `&` (AND) has higher precedence than `|` (OR)
   - Always wrap conditions in parentheses
7. **Explore data with value_counts()** before detailed analysis
8. **Use crosstab for categorical relationships**
9. **Group by for aggregated statistics** by category
10. **Chain operations carefully** - sometimes breaking into steps is clearer

---

## Common Pitfalls to Avoid

### Level 1
❌ **Don't forget to assign results** - Most operations return new DataFrames
❌ **Avoid modifying original data** unless using `inplace=True`
❌ **Check for NaN values** after merge/concat operations
❌ **Ensure consistent data types** across columns
❌ **Be careful with index alignment** during operations

### Level 2
❌ **Don't confuse iloc and loc** - iloc uses positions, loc uses labels
❌ **Avoid forgetting parentheses** in multiple condition filters
❌ **Don't use `and`/`or`** - Use `&`/`|` for DataFrame conditions
❌ **Remember the difference** between `df["col"]` and `df[["col"]]`
❌ **Don't assume data is clean** - always check for nulls and dtypes
❌ **Avoid hardcoding indices** - use loc/iloc appropriately
❌ **Don't forget normalize=True** when you want proportions
❌ **Check your filter results** - ensure you're getting expected rows

---

## Quick Reference Guide

### Reading Data
```python
df = pd.read_csv("file.csv")
df = pd.read_excel("file.xlsx")
```

### Inspecting Data
```python
df.head()              # First 5 rows
df.tail()              # Last 5 rows
df.shape               # (rows, columns)
df.columns             # Column names
df.dtypes              # Data types
df.isnull().sum()      # Count null values
```

### Selecting Data
```python
df["col"]              # Series
df[["col"]]            # DataFrame
df[["col1", "col2"]]   # Multiple columns
df.iloc[0, 1]          # Position-based
df.loc[0, "col"]       # Label-based
```

### Filtering Data
```python
df[df["col"] == value]                    # Single condition
df[(df["col1"] > 5) & (df["col2"] == 'A')]  # AND
df[(df["col1"] > 5) | (df["col2"] == 'A')]  # OR
df[~(df["col"] == value)]                 # NOT
```

### Analysis
```python
df["col"].unique()              # Unique values
df["col"].value_counts()        # Count occurrences
df["col"].value_counts(normalize=True)  # Proportions
pd.crosstab(df["col1"], df["col2"])     # Cross-tabulation
df.groupby("col")["value"].mean()       # Group by aggregation
```

---
