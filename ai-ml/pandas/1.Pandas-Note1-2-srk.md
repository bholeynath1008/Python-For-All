# Pandas Tutorial - Complete Guide

## Table of Contents

### Level 1: Fundamentals
- [Introduction](#introduction)
  - Importing Libraries
- [Pandas Series](#pandas-series)
  - What is a Series?
  - Creating Series from List
  - Creating Series with Custom Index
  - Creating Series from 1D Array
  - Creating Series from Dictionary
- [Pandas DataFrame](#pandas-dataframe)
  - What is a DataFrame?
  - Creating DataFrame from Dictionary
  - Creating DataFrame from Nested List
  - Creating DataFrame from 2D Array
- [DataFrame Operations](#dataframe-operations)
  - Index Operations (set_index, reset_index)
  - Drop Operations (rows and columns)
  - Sorting Values (ascending and descending)
- [Combining DataFrames](#combining-dataframes)
  - Concatenation (axis=0 and axis=1)
  - Using ignore_index
- [Merging DataFrames](#merging-dataframes)
  - Left Join
  - Right Join
  - Inner Join
  - Outer Join

### Level 2: Advanced Operations
- [Loading Data](#loading-data)
  - Reading CSV Files
  - Reading Excel Files
  - Viewing Data (head, tail)
- [DataFrame Inspection](#dataframe-inspection)
  - Viewing Columns and Data Types
  - Checking for Null Values
  - Renaming Columns
- [Data Selection and Indexing](#data-selection-and-indexing)
  - Selecting Single Column (Series vs DataFrame)
  - Converting Series to Array
  - Using iloc() - Position-based Indexing
  - Using loc() - Label-based Indexing
- [Data Filtering](#data-filtering)
  - Single Condition Filtering
  - Multiple Conditions (AND/OR)
  - Negation Filtering
- [Data Analysis](#data-analysis)
  - Unique Values
  - Value Counts
  - Crosstab Analysis
  - Group By Operations
- [Best Practices and Tips](#best-practices-and-tips)

---

## Introduction

### Import Libraries
```python
import numpy as np
import pandas as pd
```

---

## Pandas Series

### What is a Pandas Series?
- A one-dimensional (1D) array holding data of any type
- Similar to a column in a table

### Rule: Understanding dtype
- `dtype: int64` → Integer numbers (64-bit)
- `dtype: int32` → Integer numbers (32-bit, from NumPy)
- `dtype: float64` → Decimal numbers
- `dtype: object` → Text/strings or mixed types
### 1. Creating Series from a List

```python
l = [10, 20, 30]
s = pd.Series(l)
print(s)
```

**Output:**
```
0    10
1    20
2    30
dtype: int64
```

**Check type:**
```python
type(s)  # pandas.core.series.Series
```

**Check shape:**
```python
s.shape  # (3,)
```

### 2. Creating Series with Custom Index

```python
l = [10, 20, 30]
s = pd.Series(l, index=["a", "b", "c"])
print(s)
```

**Output:**
```
a    10
b    20
c    30
dtype: int64
```

### 3. Creating Series from 1D Array

```python
a = np.array([10, 20, 30])
s = pd.Series(a)
print(s)
```

**Output:**
```
0    10
1    20
2    30
dtype: int32
```

**With custom index:**
```python
a = np.array([10, 20, 30])
s = pd.Series(a, index=["a", "b", "c"])
print(s)
```

**Output:**
```
a    10
b    20
c    30
dtype: int32
```

### 4. Creating Series from Dictionary

```python
d = {'a': 10, 'b': 20, 'c': 30}
s = pd.Series(d)
print(s)
```

**Output:**
```
a    10
b    20
c    30
dtype: int64
```

---

## Pandas DataFrame

### What is a DataFrame?
- A 2-dimensional data structure (like a 2D array or table)
- Contains rows and columns

### 1. Creating DataFrame from Dictionary

**Basic example:**
```python
d = {'col1': [1, 2], 'col2': [3, 4]}
s = pd.Series(d)
print(s)
```

**Output:**
```
col1    [1, 2]
col2    [3, 4]
dtype: object
```

**Creating actual DataFrame:**
```python
d = {'col1': [1, 2], 'col2': [3, 4]}
df = pd.DataFrame(d)
df
```

**Output:**
```
   col1  col2
0     1     3
1     2     4
```

**Check type:**
```python
type(df)  # pandas.core.frame.DataFrame
```

**Check shape:**
```python
df.shape  # (2, 2)
```

### 2. Creating DataFrame from Nested List

```python
data = [[1, 2, 3], [4, 5, 6]]
df1 = pd.DataFrame(data, columns=["a", "b", "c"])
df1
```

**Output:**
```
   a  b  c
0  1  2  3
1  4  5  6
```

### 3. Creating DataFrame from 2D Array

```python
arr_2d = np.array([[1, 2, 3], [4, 5, 6]])
df2 = pd.DataFrame(arr_2d, index=["a", "b"], columns=["s", "r", "k"])
df2
```

**Output:**
```
   s  r  k
a  1  2  3
b  4  5  6
```

---

## DataFrame Operations

### Sample DataFrame

```python
df = pd.DataFrame({
    'Age': [22, 30, 23, 25, 24],
    'Salary': [28000, 17000, 46000, 42000, 55000],
    'Gender': ["M", "F", "M", "M", "F"]
})
df
```

**Output:**
```
   Age  Salary Gender
0   22   28000      M
1   30   17000      F
2   23   46000      M
3   25   42000      M
4   24   55000      F
```

### Index Operations

#### Set Index
```python
df1 = df.set_index("Age")
df1
```

**Output:**
```
     Salary Gender
Age                
22    28000      M
30    17000      F
23    46000      M
25    42000      M
24    55000      F
```

#### Reset Index
```python
df1.reset_index()
```

**Output:**
```
   Age  Salary Gender
0   22   28000      M
1   30   17000      F
2   23   46000      M
3   25   42000      M
4   24   55000      F
```

### Drop Operations

#### Drop Single Row
```python
df1 = df.drop(index=[3])
df1
```

**Output:**
```
   Age  Salary Gender
0   22   28000      M
1   30   17000      F
2   23   46000      M
4   24   55000      F
```

#### Drop Multiple Rows
```python
df1 = df.drop(index=[0, 1, 2])
df1
```

**Output:**
```
   Age  Salary Gender
3   25   42000      M
4   24   55000      F
```

#### Drop Single Column
```python
df1 = df.drop(columns=["Age"])
df1
```

**Output:**
```
   Salary Gender
0   28000      M
1   17000      F
2   46000      M
3   42000      M
4   55000      F
```

#### Drop Multiple Columns
```python
df1 = df.drop(columns=["Age", "Gender"])
df1
```

**Output:**
```
   Salary
0   28000
1   17000
2   46000
3   42000
4   55000
```

### Sorting Values

#### Ascending Order
```python
# Sorting in ascending order
df.sort_values(by='Age', ascending=True)
```

**Output:**
```
   Age  Salary Gender
0   22   28000      M
2   23   46000      M
4   24   55000      F
3   25   42000      M
1   30   17000      F
```

#### Descending Order
```python
# Sorting in descending order
df.sort_values(by='Age', ascending=False)
```

**Output:**
```
   Age  Salary Gender
1   30   17000      F
3   25   42000      M
4   24   55000      F
2   23   46000      M
0   22   28000      M
```

---

## Combining DataFrames

### Sample DataFrames

**DataFrame 1:**
```python
df1 = pd.DataFrame({
    "city": ["mumbai", "delhi", "banglore", "hyderabad"],
    "temperature": [32, 45, 40, 36]
})
df1
```

**Output:**
```
       city  temperature
0    mumbai           32
1     delhi           45
2  banglore           40
3  hyderabad          36
```

**DataFrame 2:**
```python
df2 = pd.DataFrame({
    "city": ["delhi", "mumbai", "banglore", "chennai"],
    "humidity": [68, 65, 75, 70]
})
df2
```

**Output:**
```
       city  humidity
0     delhi        68
1    mumbai        65
2  banglore        75
3   chennai        70
```

### Concatenation

#### Concatenate along rows (axis=1)
```python
pd.concat([df1, df2], axis=1)
```

**Output:**
```
       city  temperature      city  humidity
0    mumbai           32     delhi        68
1     delhi           45    mumbai        65
2  banglore           40  banglore        75
3  hyderabad          36   chennai        70
```

#### Concatenate along columns (axis=0)
```python
pd.concat([df1, df2], axis=0)
```

**Output:**
```
       city  temperature  humidity
0    mumbai         32.0       NaN
1     delhi         45.0       NaN
2  banglore         40.0       NaN
3  hyderabad        36.0       NaN
0     delhi          NaN      68.0
1    mumbai          NaN      65.0
2  banglore          NaN      75.0
3   chennai          NaN      70.0
```

#### Concatenate with ignore_index=True
```python
pd.concat([df1, df2], ignore_index=True)
```

**Output:**
```
       city  temperature  humidity
0    mumbai         32.0       NaN
1     delhi         45.0       NaN
2  banglore         40.0       NaN
3  hyderabad        36.0       NaN
4     delhi          NaN      68.0
5    mumbai          NaN      65.0
6  banglore          NaN      75.0
7   chennai          NaN      70.0
```

---

## Merging DataFrames

### Left Join
```python
left_df = pd.merge(df1, df2, on='city', how='left')
left_df
```

**Output:**
```
       city  temperature  humidity
0    mumbai           32      65.0
1     delhi           45      68.0
2  banglore           40      75.0
3  hyderabad          36       NaN
```

### Right Join
```python
right_df = pd.merge(df1, df2, on='city', how='right')
right_df
```

**Output:**
```
       city  temperature  humidity
0     delhi         45.0        68
1    mumbai         32.0        65
2  banglore         40.0        75
3   chennai          NaN        70
```

### Inner Join
```python
# Inner Join -- common data records
inner_df = pd.merge(df1, df2, on="city", how="inner")
inner_df
```

**Output:**
```
       city  temperature  humidity
0    mumbai           32        65
1     delhi           45        68
2  banglore           40        75
```

### Outer Join
```python
# Outer Join -- all records of both dataframes
outer_df = pd.merge(df1, df2, on='city', how='outer')
outer_df
```

**Output:**
```
       city  temperature  humidity
0    mumbai         32.0      65.0
1     delhi         45.0      68.0
2  banglore         40.0      75.0
3  hyderabad        36.0       NaN
4   chennai          NaN      70.0
```

---

# Level 2: Advanced Operations

## Loading Data

### Reading CSV Files

**Option 1: With full path**
```python
df = pd.read_csv("C:\\01. Python\\tips.csv")
```

**Option 2: Just filename (if in same directory)**
```python
df = pd.read_csv("tips.csv")
```

### Reading Excel Files

```python
df = pd.read_excel("tips.xlsx")
```

### Viewing Data

#### Head - First 5 rows
```python
df.head()
```

**Output:**
```
   total_bill   tip     sex smoker  day    time  size
0       16.99  1.01  Female     No  Sun  Dinner     2
1       10.34  1.66    Male     No  Sun  Dinner     3
2       21.01  3.50    Male     No  Sun  Dinner     3
3       23.68  3.31    Male     No  Sun  Dinner     2
4       24.59  3.61  Female     No  Sun  Dinner     4
```

#### Tail - Last 5 rows
```python
df.tail()
```

**Output:**
```
     total_bill   tip     sex smoker   day    time  size
239       29.03  5.92    Male     No   Sat  Dinner     3
240       27.18  2.00  Female    Yes   Sat  Dinner     2
241       22.67  2.00    Male    Yes   Sat  Dinner     2
242       17.82  1.75    Male     No   Sat  Dinner     2
243       18.78  3.00  Female     No  Thur  Dinner     2
```

---

## DataFrame Inspection

### Viewing Column Names

```python
df.columns
```

**Output:**
```
Index(['total_bill', 'tip', 'sex', 'smoker', 'day', 'time', 'size'], dtype='object')
```

**Alternative method:**
```python
df.keys()
```

**Output:**
```
Index(['total_bill', 'tip', 'sex', 'smoker', 'day', 'time', 'size'], dtype='object')
```

### Renaming Columns

```python
df = df.rename(columns={'sex': 'gender', 'size': 'no_of_members'})
df.columns
```

**Output:**
```
Index(['total_bill', 'tip', 'gender', 'smoker', 'day', 'time', 'no_of_members'], dtype='object')
```

### Checking Data Types

```python
df.dtypes
```

**Output:**
```
total_bill       float64
tip              float64
gender            object
smoker            object
day               object
time              object
no_of_members      int64
dtype: object
```

### Checking for Null Values

```python
df.isnull().sum()
```

**Output:**
```
total_bill       0
tip              0
gender           0
smoker           0
day              0
time             0
no_of_members    0
dtype: int64
```

---

## Data Selection and Indexing

### Selecting a Single Column

#### Returns a Series
```python
df["total_bill"]
```

**Output:**
```
0      16.99
1      10.34
2      21.01
3      23.68
4      24.59
       ...
240    27.18
241    22.67
242    17.82
243    18.78
Name: total_bill, Length: 244, dtype: float64
```

#### Returns a DataFrame
```python
df[["total_bill"]]
```

**Output:**
```
     total_bill
0         16.99
1         10.34
2         21.01
3         23.68
4         24.59
...         ...
240       27.18
241       22.67
242       17.82
243       18.78

244 rows × 1 columns
```

### Converting Series to NumPy Array

```python
df['total_bill'].values
```

**Output:**
```python
array([16.99, 10.34, 21.01, 23.68, 24.59, ..., 27.18, 22.67, 17.82, 18.78])
```

### Selecting Multiple Columns

```python
df[["gender", "smoker"]]
```

**Output:**
```
     gender smoker
0    Female     No
1      Male     No
2      Male     No
3      Male     No
4    Female     No
...     ...    ...
240  Female    Yes
241    Male    Yes
242    Male     No
243  Female     No

244 rows × 2 columns
```

---

## Position-Based Indexing: iloc()

`iloc()` uses **integer positions** to access data (like array indexing).

### Selecting Single Element

```python
df.iloc[0, 2]
```

**Output:**
```
'Female'
```

### Selecting Single Row

```python
df.iloc[0]
```

**Output:**
```
total_bill     16.99
tip             1.01
gender        Female
smoker            No
day              Sun
time          Dinner
no_of_members      2
Name: 0, dtype: object
```

### Selecting Range of Rows and Specific Column

```python
df.iloc[0:5, 2]
```

**Output:**
```
0    Female
1      Male
2      Male
3      Male
4    Female
Name: gender, dtype: object
```

### Selecting with Step

```python
df.iloc[4:23:6, 2]
```

**Output:**
```
4     Female
10    Female
16    Female
22      Male
Name: gender, dtype: object
```

### Selecting Specific Rows and Columns

```python
df.iloc[[4, 10, 16, 22], [2, 3]]
```

**Output:**
```
   gender smoker
4  Female     No
10 Female     No
16 Female     No
22   Male    Yes
```

### Selecting All Rows, Specific Column

```python
df.iloc[:, 0]
```

**Output:**
```
0      16.99
1      10.34
2      21.01
...
241    22.67
242    17.82
243    18.78
Name: total_bill, Length: 244, dtype: float64
```

### Selecting All Rows, Multiple Columns

```python
df.iloc[:, [2, 3]]
```

**Output:**
```
     gender smoker
0    Female     No
1      Male     No
2      Male     No
...     ...    ...
241    Male    Yes
242    Male     No
243  Female     No

244 rows × 2 columns
```

---

## Label-Based Indexing: loc()

`loc()` uses **labels/names** to access data.

### Selecting Specific Rows and Columns by Label

```python
df.loc[[4, 10, 16, 22], ["gender", 'smoker']]
```

**Output:**
```
   gender smoker
4  Female     No
10 Female     No
16 Female     No
22   Male    Yes
```

### Selecting with Slice and Step

```python
df.loc[4:23:6, ["gender", 'smoker']]
```

**Output:**
```
   gender smoker
4  Female     No
10 Female     No
16 Female     No
22   Male    Yes
```

### Selecting All Rows, Specific Column

```python
df.loc[:, "total_bill"]
```

**Output:**
```
0      16.99
1      10.34
2      21.01
...
241    22.67
242    17.82
243    18.78
Name: total_bill, Length: 244, dtype: float64
```

### Selecting All Rows, Multiple Columns

```python
df.loc[:, ["gender", 'smoker']]
```

**Output:**
```
     gender smoker
0    Female     No
1      Male     No
2      Male     No
...     ...    ...
241    Male    Yes
242    Male     No
243  Female     No

244 rows × 2 columns
```

---

## Data Filtering

### Single Condition Filtering

```python
df[df["gender"] == "Male"]
```

**Output:**
```
     total_bill   tip  gender smoker   day    time  no_of_members
0         16.99  1.01    Male     No   Sun  Dinner              2
1         10.34  1.66    Male     No   Sun  Dinner              3
...         ...   ...     ...    ...   ...     ...            ...

157 rows × 7 columns
```

**Filter by numeric condition:**
```python
df[df['tip'] >= 7]
```

**Output:**
```
     total_bill    tip  gender smoker  day    time  no_of_members
23        39.42   7.58    Male     No  Sat  Dinner              4
44        30.40   5.60    Male     No  Sun  Dinner              4
...          ...    ...     ...    ...  ...     ...            ...

7 rows × 7 columns
```

### Negation Filtering (NOT)

```python
df[~(df['tip'] >= 7)]
```

**Output:**
```
     total_bill   tip  gender smoker   day    time  no_of_members
0         16.99  1.01  Female     No   Sun  Dinner              2
1         10.34  1.66    Male     No   Sun  Dinner              3
...         ...   ...     ...    ...   ...     ...            ...

237 rows × 7 columns
```

**Alternative:**
```python
df[df['tip'] < 7]
```

### Multiple Conditions

#### AND Condition (&)

```python
df[(df['tip'] >= 3) & (df["gender"] == "Male")]
```

**Output:**
```
     total_bill    tip gender smoker  day    time  no_of_members
2         21.01   3.50   Male     No  Sun  Dinner              3
3         23.68   3.31   Male     No  Sun  Dinner              2
...          ...    ...    ...    ...  ...     ...            ...

76 rows × 7 columns
```

#### OR Condition (|)

```python
df[(df['tip'] >= 3) | (df['gender'] == "Female")]
```

**Output:**
```
     total_bill    tip  gender smoker   day    time  no_of_members
0         16.99   1.01  Female     No   Sun  Dinner              2
2         21.01   3.50    Male     No   Sun  Dinner              3
...          ...    ...     ...    ...   ...     ...            ...

169 rows × 7 columns
```

#### Complex Multiple Conditions

```python
df[(df['tip'] >= 3) & (df['gender'] == "Female") & (df['total_bill'] <= 60)]
```

**Output:**
```
     total_bill   tip  gender smoker   day    time  no_of_members
3         23.68  3.31  Female     No   Sun  Dinner              2
4         24.59  3.61  Female     No   Sun  Dinner              4
11        35.26  5.00  Female     No   Sun  Dinner              4
...          ...   ...     ...    ...   ...     ...            ...

31 rows × 7 columns
```

---

## Data Analysis

### Unique Values

```python
df['gender'].unique()
```

**Output:**
```python
array(['Female', 'Male'], dtype=object)
```

### Value Counts

**Absolute counts:**
```python
df["gender"].value_counts()
```

**Output:**
```
Male      157
Female     87
Name: gender, dtype: int64
```

**Proportions (manual calculation):**
```python
df["gender"].value_counts() / len(df)
```

**Output:**
```
Male      0.643443
Female    0.356557
Name: gender, dtype: float64
```

**Proportions (using normalize parameter):**
```python
df["gender"].value_counts(normalize=True)
```

**Output:**
```
Male      0.643443
Female    0.356557
Name: gender, dtype: float64
```

### Crosstab Analysis

**Applied on 2 discrete variables**

**Basic crosstab:**
```python
pd.crosstab(df["gender"], df["smoker"])
```

**Output:**
```
smoker     No  Yes
gender            
Female     54   33
Male       97   60
```

**With row/column totals:**
```python
pd.crosstab(df["gender"], df["smoker"], margins=True)
```

**Output:**
```
smoker     No  Yes  All
gender                 
Female     54   33   87
Male       97   60  157
All       151   93  244
```

### Group By Operations

**Grouping by category and calculating aggregate statistics:**

```python
# Grouping on basis of "gender" and calculating mean of "tip"
df.groupby('gender')["tip"].mean()
```

**Output:**
```
gender
Female    2.833448
Male      3.089618
Name: tip, dtype: float64
```

**Other aggregate functions you can use:**
- `.sum()` - Total sum
- `.mean()` - Average
- `.median()` - Median value
- `.min()` - Minimum value
- `.max()` - Maximum value
- `.count()` - Count of values
- `.std()` - Standard deviation

---

## Key Concepts and Tips

### Level 1: Fundamentals

#### Series
- **Definition**: One-dimensional labeled array
- **Creation methods**: List, NumPy array, dictionary
- **Index**: Can be default (0, 1, 2...) or custom labels
- **Use case**: Represents a single column of data

#### DataFrame
- **Definition**: Two-dimensional labeled data structure
- **Creation methods**: Dictionary, nested list, 2D NumPy array
- **Structure**: Consists of rows (index) and columns
- **Shape**: Access using `.shape` attribute (rows, columns)

#### Index Operations
- **set_index()**: Convert a column to index
- **reset_index()**: Convert index back to regular column
- **Use case**: Useful for organizing and accessing data

#### Drop Operations
- **drop(index=[...])**: Remove rows by index
- **drop(columns=[...])**: Remove columns by name
- **Tip**: Does not modify original DataFrame unless `inplace=True`

#### Sorting
- **sort_values(by='column')**: Sort by specific column
- **ascending=True**: Sort in ascending order (default)
- **ascending=False**: Sort in descending order

#### Concatenation
- **axis=0**: Stack vertically (add rows)
- **axis=1**: Stack horizontally (add columns)
- **ignore_index=True**: Reset index after concatenation

#### Merging
- **on='column'**: Specify the key column for merging
- **how='left'**: Keep all rows from left DataFrame
- **how='right'**: Keep all rows from right DataFrame
- **how='inner'**: Keep only common rows
- **how='outer'**: Keep all rows from both DataFrames

### Level 2: Advanced Operations

#### Loading Data
- **pd.read_csv()**: Load CSV files
- **pd.read_excel()**: Load Excel files
- **Path options**: Full path or just filename (if in same directory)
- **.head()**: View first 5 rows
- **.tail()**: View last 5 rows

#### Column Operations
- **df.columns**: View all column names
- **df.rename()**: Rename columns using dictionary mapping
- **df.dtypes**: Check data type of each column
- **df.isnull().sum()**: Count null values in each column

#### Data Selection
- **df["column"]**: Returns a Series (single brackets)
- **df[["column"]]**: Returns a DataFrame (double brackets)
- **.values**: Convert Series to NumPy array
- **Difference matters**: Series vs DataFrame for further operations

#### iloc() - Position-Based Indexing
- **Uses integer positions**: Like array indexing (0, 1, 2...)
- **df.iloc[row, col]**: Select specific cell
- **df.iloc[rows, cols]**: Use lists or slices
- **Syntax**: `df.iloc[0:5, [1, 3]]` - rows 0-4, columns 1 and 3

#### loc() - Label-Based Indexing
- **Uses labels/names**: Column names and index labels
- **df.loc[index, column]**: Select by name
- **More readable**: Easier to understand what you're selecting
- **Syntax**: `df.loc[:, ["col1", "col2"]]` - all rows, specific columns

#### Filtering Data
- **Single condition**: `df[df["col"] == value]`
- **Multiple AND**: `df[(condition1) & (condition2)]`
- **Multiple OR**: `df[(condition1) | (condition2)]`
- **Negation**: `df[~(condition)]` or inverse condition
- **Numeric comparisons**: `>=`, `<=`, `>`, `<`, `==`, `!=`

#### Data Analysis
- **.unique()**: Get unique values in a column
- **.value_counts()**: Count occurrences of each value
- **normalize=True**: Get proportions instead of counts
- **pd.crosstab()**: Create cross-tabulation of two variables
- **margins=True**: Add row/column totals to crosstab
- **.groupby()**: Group data by category for aggregation

---

## Best Practices

### Level 1
1. **Always check data types** using `type()` and `dtype`
2. **Verify shapes** using `.shape` before operations
3. **Use meaningful column names** for clarity
4. **Set index wisely** for better data access
5. **Choose appropriate merge type** based on your needs:
   - Use **inner** for common records only
   - Use **outer** for all records
   - Use **left/right** when one DataFrame is primary
6. **Handle NaN values** appropriately after merging/concatenating
7. **Use `ignore_index=True`** when concatenating to avoid duplicate indices

### Level 2
1. **Always inspect your data first** using `.head()`, `.tail()`, `.info()`
2. **Check for null values** before analysis using `.isnull().sum()`
3. **Know the difference** between Series and DataFrame selection
4. **Choose between iloc and loc**:
   - Use **iloc** when working with positions/indices
   - Use **loc** when working with labels/names (more readable)
5. **Use parentheses for multiple conditions** in filtering
6. **Remember operator precedence**:
   - `&` (AND) has higher precedence than `|` (OR)
   - Always wrap conditions in parentheses
7. **Explore data with value_counts()** before detailed analysis
8. **Use crosstab for categorical relationships**
9. **Group by for aggregated statistics** by category
10. **Chain operations carefully** - sometimes breaking into steps is clearer

---

## Common Pitfalls to Avoid

### Level 1
❌ **Don't forget to assign results** - Most operations return new DataFrames
❌ **Avoid modifying original data** unless using `inplace=True`
❌ **Check for NaN values** after merge/concat operations
❌ **Ensure consistent data types** across columns
❌ **Be careful with index alignment** during operations

### Level 2
❌ **Don't confuse iloc and loc** - iloc uses positions, loc uses labels
❌ **Avoid forgetting parentheses** in multiple condition filters
❌ **Don't use `and`/`or`** - Use `&`/`|` for DataFrame conditions
❌ **Remember the difference** between `df["col"]` and `df[["col"]]`
❌ **Don't assume data is clean** - always check for nulls and dtypes
❌ **Avoid hardcoding indices** - use loc/iloc appropriately
❌ **Don't forget normalize=True** when you want proportions
❌ **Check your filter results** - ensure you're getting expected rows

---

## Quick Reference Guide

### Reading Data
```python
df = pd.read_csv("file.csv")
df = pd.read_excel("file.xlsx")
```

### Inspecting Data
```python
df.head()              # First 5 rows
df.tail()              # Last 5 rows
df.shape               # (rows, columns)
df.columns             # Column names
df.dtypes              # Data types
df.isnull().sum()      # Count null values
```

### Selecting Data
```python
df["col"]              # Series
df[["col"]]            # DataFrame
df[["col1", "col2"]]   # Multiple columns
df.iloc[0, 1]          # Position-based
df.loc[0, "col"]       # Label-based
```

### Filtering Data
```python
df[df["col"] == value]                    # Single condition
df[(df["col1"] > 5) & (df["col2"] == 'A')]  # AND
df[(df["col1"] > 5) | (df["col2"] == 'A')]  # OR
df[~(df["col"] == value)]                 # NOT
```

### Analysis
```python
df["col"].unique()              # Unique values
df["col"].value_counts()        # Count occurrences
df["col"].value_counts(normalize=True)  # Proportions
pd.crosstab(df["col1"], df["col2"])     # Cross-tabulation
df.groupby("col")["value"].mean()       # Group by aggregation
```

---

*These comprehensive notes cover both fundamental and advanced Pandas operations for effective data manipulation and analysis.*
